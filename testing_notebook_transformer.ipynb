{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node predictions shape: torch.Size([50, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "# A simple GPS layer that fuses local (R-GCN) and global (Transformer) processing.\n",
    "class GPSLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_relations, nhead=8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hidden_dim (int): Dimension of node features.\n",
    "            num_relations (int): Number of relation types in the graph.\n",
    "            nhead (int): Number of attention heads in the transformer layer.\n",
    "        \"\"\"\n",
    "        super(GPSLayer, self).__init__()\n",
    "        # Local message passing using R-GCN (Relational GCN)\n",
    "        self.local = RGCNConv(hidden_dim, hidden_dim, num_relations)\n",
    "        # Global transformer: using PyTorch's TransformerEncoderLayer.\n",
    "        # Note: Transformer expects input shape (S, N, E) where S=sequence length (num_nodes) and N=batch size.\n",
    "        self.global_transformer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nhead)\n",
    "        # Two layer norms (one after each branch) for stability.\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        # LOCAL BRANCH: apply the R-GCN module.\n",
    "        local_out = self.local(x, edge_index, edge_type)\n",
    "        x = x + local_out  # residual connection\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        # GLOBAL BRANCH: apply the transformer module.\n",
    "        # Transformer expects input shape (num_nodes, batch_size, hidden_dim).\n",
    "        # We assume a single-graph (batch size = 1).\n",
    "        x_transformed = self.global_transformer(x.unsqueeze(1)).squeeze(1)\n",
    "        x = x + x_transformed  # residual connection\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "# The overall model that stacks multiple GPS layers for node prediction.\n",
    "class GraphGPSNodeClassifier(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, num_relations, nhead=8):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Input node feature dimension.\n",
    "            hidden_channels (int): Hidden (and transformer) dimension.\n",
    "            out_channels (int): Number of prediction classes (or regression output dim).\n",
    "            num_layers (int): Number of alternating GPS layers.\n",
    "            num_relations (int): Number of relation types in the graph.\n",
    "            nhead (int): Number of transformer heads.\n",
    "        \"\"\"\n",
    "        super(GraphGPSNodeClassifier, self).__init__()\n",
    "        # Initial linear embedding of input features.\n",
    "        self.embedding = nn.Linear(in_channels, hidden_channels)\n",
    "        # Stack alternating GPS layers.\n",
    "        self.layers = nn.ModuleList([\n",
    "            GPSLayer(hidden_channels, num_relations, nhead=nhead)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        # Final classifier head (applied on each node)\n",
    "        self.classifier = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Node features of shape (num_nodes, in_channels).\n",
    "            edge_index (torch.Tensor): Edge indices (2, num_edges).\n",
    "            edge_type (torch.Tensor): Edge type labels (num_edges,).\n",
    "        Returns:\n",
    "            torch.Tensor: Predictions for each node (num_nodes, out_channels).\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index, edge_type)\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage:\n",
    "# Assume:\n",
    "#   - each node has 'in_channels' features,\n",
    "#   - the graph has 'num_relations' (e.g. from your KG or other source),\n",
    "#   - we wish to classify nodes into 'out_channels' classes.\n",
    "# Replace these numbers with the ones for your application.\n",
    "in_channels = 128\n",
    "hidden_channels = 256\n",
    "out_channels = 10   # for 10-class node classification\n",
    "num_layers = 3\n",
    "num_relations = 4   # change this based on your relation vocab\n",
    "\n",
    "model = GraphGPSNodeClassifier(in_channels, hidden_channels, out_channels, num_layers, num_relations)\n",
    "\n",
    "# Dummy data for illustration:\n",
    "num_nodes = 50\n",
    "num_edges = 200\n",
    "x = torch.randn(num_nodes, in_channels)\n",
    "edge_index = torch.randint(0, num_nodes, (2, num_edges))\n",
    "edge_type = torch.randint(0, num_relations, (num_edges,))\n",
    "\n",
    "# Forward pass: node predictions\n",
    "predictions = model(x, edge_index, edge_type)\n",
    "print(\"Node predictions shape:\", predictions.shape)  # Expected: (num_nodes, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cpnet...\n",
      "Done\n",
      "Loaded 3947 allowed concept IDs from train/val data.\n"
     ]
    }
   ],
   "source": [
    "from KG_trainer_w_transformer import get_KG_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/eg\"\n",
    "source_path=f\"{DATA_PATH}/train.source\"\n",
    "target_path=f\"{DATA_PATH}/train.target\"\n",
    "model_name = \"facebook/bart-base\"\n",
    "output_dir = \"KG_finetuned_out_transformer\"\n",
    "max_len = 128\n",
    "epochs = 1\n",
    "train_batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data:   0%|          | 0/500 [00:00<?, ? examples/s]c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Preprocessing data: 100%|██████████| 500/500 [00:00<00:00, 872.19 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed dataset to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 500/500 [00:00<00:00, 100002.48 examples/s]\n",
      "Some weights of BartGraphAwareForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['graph_encoder.embedding.weight', 'graph_encoder.gps_layers.0.global_transformer.linear1.bias', 'graph_encoder.gps_layers.0.global_transformer.linear1.weight', 'graph_encoder.gps_layers.0.global_transformer.linear2.bias', 'graph_encoder.gps_layers.0.global_transformer.linear2.weight', 'graph_encoder.gps_layers.0.global_transformer.norm1.bias', 'graph_encoder.gps_layers.0.global_transformer.norm1.weight', 'graph_encoder.gps_layers.0.global_transformer.norm2.bias', 'graph_encoder.gps_layers.0.global_transformer.norm2.weight', 'graph_encoder.gps_layers.0.global_transformer.self_attn.in_proj_bias', 'graph_encoder.gps_layers.0.global_transformer.self_attn.in_proj_weight', 'graph_encoder.gps_layers.0.global_transformer.self_attn.out_proj.bias', 'graph_encoder.gps_layers.0.global_transformer.self_attn.out_proj.weight', 'graph_encoder.gps_layers.0.local.bias', 'graph_encoder.gps_layers.0.local.root', 'graph_encoder.gps_layers.0.local.weight', 'graph_encoder.gps_layers.0.norm1.bias', 'graph_encoder.gps_layers.0.norm1.weight', 'graph_encoder.gps_layers.0.norm2.bias', 'graph_encoder.gps_layers.0.norm2.weight', 'graph_encoder.gps_layers.1.global_transformer.linear1.bias', 'graph_encoder.gps_layers.1.global_transformer.linear1.weight', 'graph_encoder.gps_layers.1.global_transformer.linear2.bias', 'graph_encoder.gps_layers.1.global_transformer.linear2.weight', 'graph_encoder.gps_layers.1.global_transformer.norm1.bias', 'graph_encoder.gps_layers.1.global_transformer.norm1.weight', 'graph_encoder.gps_layers.1.global_transformer.norm2.bias', 'graph_encoder.gps_layers.1.global_transformer.norm2.weight', 'graph_encoder.gps_layers.1.global_transformer.self_attn.in_proj_bias', 'graph_encoder.gps_layers.1.global_transformer.self_attn.in_proj_weight', 'graph_encoder.gps_layers.1.global_transformer.self_attn.out_proj.bias', 'graph_encoder.gps_layers.1.global_transformer.self_attn.out_proj.weight', 'graph_encoder.gps_layers.1.local.bias', 'graph_encoder.gps_layers.1.local.root', 'graph_encoder.gps_layers.1.local.weight', 'graph_encoder.gps_layers.1.norm1.bias', 'graph_encoder.gps_layers.1.norm1.weight', 'graph_encoder.gps_layers.1.norm2.bias', 'graph_encoder.gps_layers.1.norm2.weight', 'graph_encoder.node_score.bias', 'graph_encoder.node_score.weight', 'graph_encoder.sag_attn.bias', 'graph_encoder.sag_attn.weight', 'graph_fusion_layer.bias', 'graph_fusion_layer.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\quent\\OneDrive\\Desktop\\Code\\Efficient-Common-Sense-in-LLMs-via-Knowledge-Graph-Compression\\KG_trainer_w_transformer.py:361: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = get_KG_trainer(\n",
    "    source_path=source_path,\n",
    "    target_path=target_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    max_len=max_len,\n",
    "    epochs=epochs,\n",
    "    train_batch_size=train_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/25 04:23 < 04:47, 0.04 it/s, Epoch 0.48/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_scratch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
