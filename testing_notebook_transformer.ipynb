{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cpnet...\n",
      "Done\n",
      "Loaded 3947 allowed concept IDs from train/val data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "from KG_trainer_w_transformer import get_KG_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/eg\"\n",
    "source_path=f\"{DATA_PATH}/train.source\"\n",
    "target_path=f\"{DATA_PATH}/train.target\"\n",
    "model_name = \"facebook/bart-base\"\n",
    "output_dir = \"KG_finetuned_out_transformer\"\n",
    "max_len = 128\n",
    "epochs = 1\n",
    "train_batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/eg\"\n",
    "source_path=f\"{DATA_PATH}/train.source\"\n",
    "target_path=f\"{DATA_PATH}/train.target\"\n",
    "model_name = \"facebook/bart-base\"\n",
    "output_dir = \"KG_finetuned_out_transformer\"\n",
    "max_len = 128\n",
    "epochs = 1\n",
    "train_batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing data:   0%|          | 0/500 [00:00<?, ? examples/s]c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Preprocessing data: 100%|██████████| 500/500 [00:00<00:00, 829.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed dataset to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 500/500 [00:00<00:00, 85545.67 examples/s] \n",
      "Some weights of BartGraphAwareForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['graph_encoder.embedding.weight', 'graph_encoder.gps_layers.0.global_transformer.linear1.bias', 'graph_encoder.gps_layers.0.global_transformer.linear1.weight', 'graph_encoder.gps_layers.0.global_transformer.linear2.bias', 'graph_encoder.gps_layers.0.global_transformer.linear2.weight', 'graph_encoder.gps_layers.0.global_transformer.norm1.bias', 'graph_encoder.gps_layers.0.global_transformer.norm1.weight', 'graph_encoder.gps_layers.0.global_transformer.norm2.bias', 'graph_encoder.gps_layers.0.global_transformer.norm2.weight', 'graph_encoder.gps_layers.0.global_transformer.self_attn.in_proj_bias', 'graph_encoder.gps_layers.0.global_transformer.self_attn.in_proj_weight', 'graph_encoder.gps_layers.0.global_transformer.self_attn.out_proj.bias', 'graph_encoder.gps_layers.0.global_transformer.self_attn.out_proj.weight', 'graph_encoder.gps_layers.0.local.bias', 'graph_encoder.gps_layers.0.local.root', 'graph_encoder.gps_layers.0.local.weight', 'graph_encoder.gps_layers.0.norm1.bias', 'graph_encoder.gps_layers.0.norm1.weight', 'graph_encoder.gps_layers.0.norm2.bias', 'graph_encoder.gps_layers.0.norm2.weight', 'graph_encoder.gps_layers.1.global_transformer.linear1.bias', 'graph_encoder.gps_layers.1.global_transformer.linear1.weight', 'graph_encoder.gps_layers.1.global_transformer.linear2.bias', 'graph_encoder.gps_layers.1.global_transformer.linear2.weight', 'graph_encoder.gps_layers.1.global_transformer.norm1.bias', 'graph_encoder.gps_layers.1.global_transformer.norm1.weight', 'graph_encoder.gps_layers.1.global_transformer.norm2.bias', 'graph_encoder.gps_layers.1.global_transformer.norm2.weight', 'graph_encoder.gps_layers.1.global_transformer.self_attn.in_proj_bias', 'graph_encoder.gps_layers.1.global_transformer.self_attn.in_proj_weight', 'graph_encoder.gps_layers.1.global_transformer.self_attn.out_proj.bias', 'graph_encoder.gps_layers.1.global_transformer.self_attn.out_proj.weight', 'graph_encoder.gps_layers.1.local.bias', 'graph_encoder.gps_layers.1.local.root', 'graph_encoder.gps_layers.1.local.weight', 'graph_encoder.gps_layers.1.norm1.bias', 'graph_encoder.gps_layers.1.norm1.weight', 'graph_encoder.gps_layers.1.norm2.bias', 'graph_encoder.gps_layers.1.norm2.weight', 'graph_encoder.node_score.bias', 'graph_encoder.node_score.weight', 'graph_encoder.sag_attn.bias', 'graph_encoder.sag_attn.weight', 'graph_fusion_layer.bias', 'graph_fusion_layer.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = get_KG_trainer(\n",
    "    source_path=source_path,\n",
    "    target_path=target_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    max_len=max_len,\n",
    "    epochs=epochs,\n",
    "    train_batch_size=train_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph representation before compression (updated node features):\n",
      "tensor([[[-1.8048,  2.0599, -0.0316,  ...,  0.3108,  1.9549, -1.4761],\n",
      "         [ 0.3958,  2.4800, -0.8265,  ...,  0.1205,  1.4469, -2.1992],\n",
      "         [ 0.1903,  2.0491, -0.5323,  ...,  0.2446,  2.0430, -2.9953],\n",
      "         ...,\n",
      "         [ 0.9820,  1.5473, -0.6830,  ..., -0.5453,  0.5169, -0.9303],\n",
      "         [ 0.8862,  1.7468, -0.6217,  ..., -0.3953,  0.4963, -1.3906],\n",
      "         [ 0.9472,  1.6363, -0.3907,  ..., -0.5484,  0.3173, -0.9627]],\n",
      "\n",
      "        [[ 1.7080,  2.1477,  0.0275,  ...,  0.3615,  0.1229, -0.7814],\n",
      "         [ 2.0153,  1.3635, -1.1719,  ..., -0.3646,  0.7779, -0.8729],\n",
      "         [ 1.3555,  0.4200, -0.1178,  ...,  0.2468,  0.6236, -0.1944],\n",
      "         ...,\n",
      "         [ 0.7373,  2.0571, -0.5942,  ..., -0.6615,  0.3759, -0.6777],\n",
      "         [ 0.7772,  1.7578, -0.5592,  ..., -0.5947,  0.5377, -0.9976],\n",
      "         [ 0.6285,  1.8422, -0.6173,  ..., -0.3646,  0.4755, -1.0749]],\n",
      "\n",
      "        [[-0.6977, -0.0509,  0.7494,  ..., -0.2836, -1.9097, -1.1630],\n",
      "         [-2.0988, -1.3728,  0.4327,  ..., -0.7503, -0.1437, -0.4635],\n",
      "         [-1.0470, -1.9354, -0.1365,  ..., -0.0375, -1.7182, -2.1417],\n",
      "         ...,\n",
      "         [ 0.7878,  1.7598, -0.7445,  ..., -0.5222,  0.1583, -0.7942],\n",
      "         [ 0.9735,  1.7106, -0.8192,  ..., -0.7015,  0.4892, -0.9154],\n",
      "         [ 0.7732,  1.8635, -0.5373,  ..., -0.3689,  0.4187, -0.9715]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5275,  0.9405, -0.5545,  ..., -1.4896, -1.3357, -1.0788],\n",
      "         [ 0.3989,  0.2411,  0.6894,  ..., -1.6239, -0.2813, -1.9203],\n",
      "         [-0.1153, -0.0362,  0.5133,  ..., -1.6795, -0.8958, -1.1783],\n",
      "         ...,\n",
      "         [ 0.9173,  1.7193, -0.2444,  ..., -0.2189,  0.3151, -1.1989],\n",
      "         [ 1.1199,  1.9561, -0.6738,  ..., -0.7000,  0.5272, -0.9669],\n",
      "         [ 0.8591,  1.7582, -0.4744,  ..., -0.7836,  0.4868, -1.0649]],\n",
      "\n",
      "        [[-0.1689,  0.0129,  1.2525,  ..., -2.0724,  1.2415,  0.1069],\n",
      "         [-1.3150, -0.6280,  0.8363,  ..., -0.8289,  2.0967,  0.4984],\n",
      "         [-1.7792,  0.6192,  1.0530,  ..., -1.0402,  2.3959,  0.9427],\n",
      "         ...,\n",
      "         [ 1.1322,  1.7931, -0.5730,  ..., -0.6480,  0.5236, -1.0657],\n",
      "         [ 0.9729,  1.8140, -0.3755,  ..., -0.6637,  0.0752, -1.0058],\n",
      "         [ 0.9646,  1.9644, -0.4645,  ..., -0.7283,  0.5317, -1.1636]],\n",
      "\n",
      "        [[-0.0698, -0.3385, -1.4371,  ..., -0.5673, -0.1023,  1.0107],\n",
      "         [ 1.5838, -0.2554, -0.9058,  ..., -1.6288,  0.5742,  0.9754],\n",
      "         [ 0.1072, -0.5768, -0.1277,  ..., -1.8568,  0.6042,  1.8174],\n",
      "         ...,\n",
      "         [ 1.0180,  1.6579, -0.5484,  ..., -0.6187,  0.5440, -1.2589],\n",
      "         [ 1.0864,  1.5955, -0.4718,  ..., -0.6216,  0.2485, -1.2660],\n",
      "         [ 0.8240,  1.9839, -0.7261,  ..., -0.2583,  0.5133, -1.1949]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n",
      "Compressed node representations for instance 0 (after top-k selection):\n",
      "tensor([[-0.6031, -0.1472, -0.5933,  ...,  1.3448,  1.3486,  0.3347],\n",
      "        [-0.5539,  0.0473,  0.6932,  ..., -0.2973,  1.8742, -0.9114],\n",
      "        [-0.2998,  0.6406, -0.4388,  ..., -0.1773,  2.1540, -0.1326],\n",
      "        ...,\n",
      "        [ 0.7773, -0.6063,  0.3620,  ..., -1.0818,  1.8558,  0.6021],\n",
      "        [ 0.5695,  0.9478, -0.7269,  ...,  0.6884,  2.5277, -0.9582],\n",
      "        [-0.4557,  0.9039, -2.2046,  ..., -0.0601,  1.9251, -1.2373]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 1 (after top-k selection):\n",
      "tensor([[ 2.2615,  1.0024, -0.3832,  ...,  1.7696,  0.9442,  1.0330],\n",
      "        [ 0.6788, -0.0802,  1.0401,  ..., -0.4703,  0.5657, -0.9772],\n",
      "        [ 1.4594,  2.2248, -0.8724,  ..., -0.1991,  2.1321, -0.3161],\n",
      "        ...,\n",
      "        [ 1.0297,  1.1105, -0.2996,  ...,  0.8925,  0.6198, -1.2203],\n",
      "        [ 0.5928,  0.9520, -0.6050,  ...,  0.9237,  0.3539, -0.4480],\n",
      "        [ 1.6188,  1.1458,  0.6578,  ...,  1.9546,  0.3398, -1.4398]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 2 (after top-k selection):\n",
      "tensor([[-1.0944,  1.7690,  0.6415,  ..., -0.1102, -1.2504, -1.8785],\n",
      "        [ 0.1817,  2.8565, -0.0104,  ..., -1.2686, -0.4774, -1.4203],\n",
      "        [ 0.9469,  2.6697, -0.1934,  ..., -1.1287, -1.1021, -1.6000],\n",
      "        ...,\n",
      "        [ 0.7698,  1.6997, -0.8497,  ..., -0.7503,  0.3205, -0.9671],\n",
      "        [ 1.1985,  1.9357, -0.6803,  ..., -0.8183,  0.6818, -0.8022],\n",
      "        [ 0.9388,  1.2919, -0.5115,  ..., -0.6420,  0.4754, -1.0057]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 3 (after top-k selection):\n",
      "tensor([[ 1.6838,  0.0917,  0.4980,  ...,  1.1137, -0.4168,  0.2768],\n",
      "        [ 1.4461,  0.8945, -1.5464,  ...,  2.2276, -1.1191,  0.1794],\n",
      "        [ 1.8821,  1.1422, -1.2084,  ..., -0.5086,  1.0146, -0.0039],\n",
      "        ...,\n",
      "        [ 0.9001,  2.1884, -0.7677,  ..., -0.8237,  0.3225, -1.0063],\n",
      "        [ 1.0746,  1.5183, -0.4058,  ..., -0.6026,  0.4139, -1.0709],\n",
      "        [ 0.9210,  2.0397, -0.5746,  ..., -0.6166,  0.3058, -1.2891]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 4 (after top-k selection):\n",
      "tensor([[-1.6246e+00, -2.0584e+00,  1.3231e+00,  ..., -3.1995e-05,\n",
      "          2.9545e-01, -2.2179e-01],\n",
      "        [-3.6899e-01, -5.7116e-02,  5.6415e-02,  ...,  5.7233e-01,\n",
      "          4.2378e-01, -1.3901e-01],\n",
      "        [-1.1830e+00,  7.5183e-02, -4.1212e-01,  ...,  1.6686e+00,\n",
      "         -4.9845e-01,  6.0946e-01],\n",
      "        ...,\n",
      "        [ 8.5672e-01,  1.7933e+00, -3.6213e-01,  ..., -5.3895e-01,\n",
      "          2.7237e-01, -7.0215e-01],\n",
      "        [ 9.8814e-01,  1.5096e+00, -7.1641e-01,  ..., -1.1462e-01,\n",
      "          3.7443e-01, -9.4571e-01],\n",
      "        [ 1.0745e+00,  1.9063e+00, -6.2235e-01,  ..., -8.0332e-01,\n",
      "          1.7184e-01, -1.2436e+00]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 5 (after top-k selection):\n",
      "tensor([[-0.4312,  0.0076, -0.4062,  ...,  0.1612,  1.1006, -0.3941],\n",
      "        [ 1.1061,  1.4012, -0.5173,  ..., -0.7925,  0.3647, -1.1495],\n",
      "        [ 1.0571,  1.9063, -0.3987,  ..., -0.7820,  0.2026, -1.2805],\n",
      "        ...,\n",
      "        [ 0.6695,  1.5508, -0.5654,  ..., -0.9964,  0.4074, -1.0708],\n",
      "        [ 0.9583,  2.0111, -0.6998,  ..., -0.6800,  0.2904, -1.3638],\n",
      "        [ 0.8227,  1.7182, -0.4502,  ..., -0.6246,  0.6179, -0.9202]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 6 (after top-k selection):\n",
      "tensor([[-0.5484,  0.6362,  1.9513,  ...,  0.1894,  0.6919,  2.3892],\n",
      "        [-0.2184,  1.1769,  2.2571,  ..., -1.2192,  0.0748,  1.4026],\n",
      "        [ 0.1679,  1.4829,  1.6996,  ..., -0.1209,  0.0513,  1.7977],\n",
      "        ...,\n",
      "        [ 1.9159, -0.7526, -0.2007,  ..., -0.3191, -0.5785,  0.6479],\n",
      "        [ 0.3073,  0.4126, -0.5315,  ...,  1.4919,  0.7423, -0.6957],\n",
      "        [ 1.0916,  1.3746, -0.6976,  ..., -0.5171,  0.6289, -0.9898]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 7 (after top-k selection):\n",
      "tensor([[ 0.5663, -0.0395, -0.6958,  ..., -2.4625, -2.1004,  0.0409],\n",
      "        [ 0.1367,  1.1839,  0.1063,  ..., -1.7441, -1.4022,  0.3911],\n",
      "        [ 1.2447, -0.1056,  0.2893,  ..., -0.8882, -1.8093,  0.6919],\n",
      "        ...,\n",
      "        [ 0.2492,  0.6286, -1.5380,  ...,  0.2561, -1.5992,  0.7282],\n",
      "        [-0.1650, -1.7523, -0.0821,  ...,  0.0894,  2.3571, -0.0810],\n",
      "        [ 1.0832,  1.6385, -0.8460,  ..., -0.4956,  0.1026, -1.0731]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 8 (after top-k selection):\n",
      "tensor([[-0.5621,  1.0462,  0.8090,  ..., -1.7438, -0.0767, -1.4163],\n",
      "        [-2.2289,  1.0124, -1.0750,  ..., -1.1273,  0.6457, -0.3734],\n",
      "        [ 0.3018,  0.0516, -1.2833,  ...,  0.3377, -0.2659, -0.3219],\n",
      "        ...,\n",
      "        [-1.6784,  0.1244, -0.1271,  ..., -1.6935, -1.4138, -1.8375],\n",
      "        [-0.9536, -0.0320, -0.1782,  ...,  0.6721, -1.5188, -0.8310],\n",
      "        [ 0.8050,  1.7027, -0.6379,  ..., -0.5999,  0.5233, -0.9279]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 9 (after top-k selection):\n",
      "tensor([[ 0.4990,  0.3114,  0.3747,  ...,  0.1351,  0.0394, -2.2340],\n",
      "        [ 0.7398,  0.4730, -0.2064,  ..., -1.7963,  0.4963, -1.7783],\n",
      "        [ 1.8988,  0.5022, -1.6571,  ..., -0.8889, -0.0425, -2.1167],\n",
      "        ...,\n",
      "        [ 0.3245,  1.0545, -2.4385,  ..., -0.0909, -1.0286, -0.5940],\n",
      "        [ 1.4578,  0.7873, -0.8225,  ...,  0.1151,  1.3831, -1.6015],\n",
      "        [ 1.1887,  0.5779,  0.5175,  ...,  0.9511, -0.7548, -1.2692]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 10 (after top-k selection):\n",
      "tensor([[ 0.6046, -0.0154,  0.2155,  ...,  0.0931, -0.1995, -2.3209],\n",
      "        [ 1.9737, -0.2017, -0.4011,  ...,  0.5157, -0.9060, -1.4561],\n",
      "        [ 1.1067, -0.0977, -0.3160,  ..., -1.8926,  0.1208, -1.8521],\n",
      "        ...,\n",
      "        [ 2.0865,  1.2407, -0.8254,  ..., -0.6534, -0.6704, -1.6112],\n",
      "        [ 2.3868, -0.1691, -0.1574,  ..., -1.9943,  0.0895, -0.9366],\n",
      "        [ 2.3736, -0.0949, -0.2176,  ...,  0.1218, -0.2549, -1.6471]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 11 (after top-k selection):\n",
      "tensor([[ 0.4316,  1.7732, -1.6929,  ..., -1.8455, -2.4679,  0.9372],\n",
      "        [-0.4790,  0.5131, -0.1358,  ...,  0.2535,  0.7440,  2.1989],\n",
      "        [ 0.2941,  0.2827,  0.1103,  ..., -1.1066, -0.2511,  0.8126],\n",
      "        ...,\n",
      "        [ 0.4985,  1.8143, -1.2175,  ..., -2.0903, -1.2264,  0.5653],\n",
      "        [-0.6228, -0.1397, -1.9404,  ...,  0.2564, -0.2996,  0.3668],\n",
      "        [ 1.1076,  0.9522, -0.5361,  ...,  0.0131,  0.6610,  1.0526]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 12 (after top-k selection):\n",
      "tensor([[-0.1013,  1.8342,  0.4307,  ..., -1.5600, -0.5427,  0.3176],\n",
      "        [ 0.1047, -0.0118,  0.7526,  ..., -0.9405,  0.3558, -0.9155],\n",
      "        [ 1.1810,  1.3500, -0.7368,  ..., -0.4432, -0.5883,  0.0507],\n",
      "        ...,\n",
      "        [ 0.4685,  2.3589,  0.1674,  ...,  0.0416, -0.7280, -0.8297],\n",
      "        [ 1.0872,  1.9444, -0.5021,  ..., -0.8807,  0.4836, -1.2483],\n",
      "        [ 1.1053,  1.9455, -0.6498,  ..., -0.8262,  0.5274, -0.9901]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 13 (after top-k selection):\n",
      "tensor([[ 0.9247,  1.3786, -0.6090,  ..., -0.9497,  0.5219, -1.0616],\n",
      "        [ 0.8104,  2.1041, -0.3848,  ..., -0.8310,  0.0845, -1.1630],\n",
      "        [ 0.8944,  1.8551, -0.6110,  ..., -0.8026,  0.5238, -0.9806],\n",
      "        ...,\n",
      "        [ 0.8944,  1.9937, -0.5674,  ..., -0.5848,  0.5116, -0.9345],\n",
      "        [ 0.9431,  1.8116, -0.4778,  ..., -0.9342,  0.4125, -1.4361],\n",
      "        [ 1.0616,  1.9856, -0.5721,  ..., -0.7899,  0.5901, -1.2708]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 14 (after top-k selection):\n",
      "tensor([[-1.6780e+00,  1.3669e+00,  1.0787e+00,  ..., -8.6843e-01,\n",
      "         -1.5689e-01,  3.6583e-01],\n",
      "        [-1.0279e+00,  2.0330e+00,  9.0234e-02,  ..., -6.6322e-01,\n",
      "         -1.0925e+00,  2.2251e-01],\n",
      "        [-2.5666e+00,  5.9871e-01,  1.4766e+00,  ...,  3.0948e-01,\n",
      "         -6.8590e-01,  2.7723e-01],\n",
      "        ...,\n",
      "        [ 1.2184e+00,  1.6458e+00, -8.1222e-01,  ..., -5.6412e-01,\n",
      "          2.6994e-01, -1.2248e+00],\n",
      "        [-1.0836e+00, -2.4140e-03,  6.5445e-01,  ..., -7.3773e-01,\n",
      "          7.2834e-01,  4.8343e-01],\n",
      "        [ 8.8657e-01,  1.6739e+00, -7.3480e-01,  ..., -7.1722e-01,\n",
      "          5.0605e-01, -9.1498e-01]], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 15 (after top-k selection):\n",
      "tensor([[-1.3464, -2.2657,  0.8678,  ..., -1.9996,  1.0848,  0.5010],\n",
      "        [ 0.8270,  1.8516, -0.8208,  ..., -0.6108,  0.4309, -0.9729],\n",
      "        [ 0.9416,  1.7678, -0.7588,  ..., -0.7377,  0.5950, -1.0340],\n",
      "        ...,\n",
      "        [ 0.8707,  1.9214, -0.6056,  ..., -0.6783,  0.5769, -1.1041],\n",
      "        [ 0.9535,  2.0317, -0.4580,  ..., -0.7524,  0.5164, -1.0631],\n",
      "        [ 0.9429,  1.9138, -0.5733,  ..., -0.7507,  0.3821, -1.1067]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 16 (after top-k selection):\n",
      "tensor([[-1.6766, -1.3974, -2.1367,  ...,  0.8223, -1.5902, -0.8028],\n",
      "        [-0.5266,  0.1654, -0.1202,  ...,  0.9654, -1.6618, -0.5514],\n",
      "        [-1.7381, -0.6829, -0.8654,  ...,  2.3221, -0.9140,  0.9819],\n",
      "        ...,\n",
      "        [ 0.2448, -1.2739, -0.9597,  ...,  0.5762, -2.5544, -1.3009],\n",
      "        [-1.4255, -0.3786, -1.7854,  ...,  1.0780, -2.2620, -1.6893],\n",
      "        [-1.0489, -1.9333, -1.2179,  ...,  0.7350, -1.2661, -0.4855]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 17 (after top-k selection):\n",
      "tensor([[-0.3846, -1.0348,  0.6236,  ..., -1.3573, -0.3526, -1.4836],\n",
      "        [ 0.9791,  1.7916, -0.6622,  ..., -0.8991,  0.4892, -0.9193],\n",
      "        [-0.5540, -1.0683,  0.3969,  ..., -2.0020,  0.2793, -1.3392],\n",
      "        ...,\n",
      "        [ 0.9096,  1.8860, -0.3936,  ..., -0.6425,  0.4913, -1.1228],\n",
      "        [ 1.0915,  1.5715, -0.8093,  ..., -0.8371,  0.4195, -1.2890],\n",
      "        [ 1.0751,  1.7109, -0.5151,  ..., -0.7448,  0.4604, -0.6377]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 18 (after top-k selection):\n",
      "tensor([[-0.3063,  0.1091,  1.4061,  ..., -2.0250,  0.2330,  0.6215],\n",
      "        [-0.9748,  0.7173,  1.2872,  ..., -1.8439,  0.3355,  0.5245],\n",
      "        [-0.4213,  1.0019,  0.7579,  ..., -1.5695,  2.3270,  0.4129],\n",
      "        ...,\n",
      "        [ 0.7779,  1.3219, -0.4973,  ..., -0.2564,  0.2197, -1.0559],\n",
      "        [ 1.1814,  1.8754, -0.5186,  ..., -0.5742,  0.3772, -0.7560],\n",
      "        [ 0.7318,  2.1033, -0.6626,  ..., -0.6821,  0.1454, -0.9964]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Compressed node representations for instance 19 (after top-k selection):\n",
      "tensor([[ 1.3557,  0.2135,  0.1286,  ...,  0.0683, -0.1606, -0.9215],\n",
      "        [ 0.1692,  0.4683, -0.6983,  ..., -1.4548,  0.1827,  1.0400],\n",
      "        [ 1.3850,  0.5665, -0.3898,  ..., -0.5120,  0.0166, -1.6557],\n",
      "        ...,\n",
      "        [ 0.8491,  2.1834, -0.3546,  ..., -0.7512,  0.3158, -0.9327],\n",
      "        [ 0.9091,  1.9943, -0.5166,  ..., -0.7224,  0.4809, -1.2170],\n",
      "        [ 0.9862,  2.0642, -0.4495,  ..., -0.6948,  0.4455, -0.9551]],\n",
      "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Pooled graph representation:\n",
      "tensor([[[-0.1141,  0.4774, -0.1429,  ...,  0.3577,  1.3334, -0.2079]],\n",
      "\n",
      "        [[ 1.6203,  1.5476, -0.1285,  ...,  0.6293,  0.5864, -0.5680]],\n",
      "\n",
      "        [[-0.1820,  1.8349, -0.1241,  ..., -0.3125, -0.6351, -1.8638]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8890,  1.6529, -0.4904,  ..., -0.7983,  0.3989, -1.0914]],\n",
      "\n",
      "        [[ 0.4052,  1.3861, -0.0870,  ..., -0.9939,  0.7887, -0.6344]],\n",
      "\n",
      "        [[ 0.9332,  1.2970, -0.6369,  ..., -0.6712,  0.4169, -0.5092]]],\n",
      "       device='cuda:0', grad_fn=<StackBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\transformers\\trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\transformers\\trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2524\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2525\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2529\u001b[0m )\n\u001b[0;32m   2530\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2531\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2534\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2535\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2537\u001b[0m ):\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2539\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\transformers\\trainer.py:3712\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_accepts_loss_kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3710\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m-> 3712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\accelerate\\accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2246\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_scratch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
