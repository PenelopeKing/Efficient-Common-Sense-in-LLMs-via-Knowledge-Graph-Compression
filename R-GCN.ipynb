{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b65f8e-ab2a-4b8e-a4f4-2f53092215eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\torch_geometric\\typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "c:\\Users\\quent\\anaconda3\\envs\\capstone_scratch_2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import RGCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import random\n",
    "import torch.optim as optim\n",
    "\n",
    "cpnet_path = \"data/cpnet.graph\"\n",
    "cpnet = None\n",
    "cpnet_simple = None\n",
    "\n",
    "# taken from quentin lol - changed a little\n",
    "def load_cpnet():\n",
    "    global cpnet, cpnet_simple\n",
    "    print(\"Loading cpnet...\")\n",
    "    with open(cpnet_path, \"rb\") as f:\n",
    "        cpnet = pickle.load(f)\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Build an undirected version\n",
    "    cpnet_simple = nx.Graph()\n",
    "    for u, v, data in cpnet.edges(data=True):\n",
    "        w = data[\"weight\"] if \"weight\" in data else 1.0\n",
    "        if cpnet_simple.has_edge(u, v):\n",
    "            cpnet_simple[u][v][\"weight\"] += w\n",
    "        else:\n",
    "            cpnet_simple.add_edge(u, v, weight=w)\n",
    "    \n",
    "    return cpnet_simple, cpnet.edges(data=True)\n",
    "\n",
    "# converting to pyG cause its directly usable for models like R-GCN\n",
    "def convert_to_pyg(cpnet):\n",
    "    node_map = {node: i for i, node in enumerate(cpnet.nodes())}\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    rel_map = {}\n",
    "    \n",
    "    for u, v, data in cpnet.edges(data=True):\n",
    "        u_idx, v_idx = node_map[u], node_map[v]\n",
    "        edge_index.append([u_idx, v_idx])\n",
    "        rel = data.get(\"rel\", \"generic\")\n",
    "        if rel not in rel_map:\n",
    "            rel_map[rel] = len(rel_map)\n",
    "        edge_attr.append(rel_map[rel])\n",
    "    \n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.long)\n",
    "    \n",
    "    return Data(edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(node_map)), rel_map\n",
    "\n",
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, in_channels, hidden_channels, out_channels):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.conv1 = RGCNConv(in_channels, hidden_channels, num_relations)\n",
    "        self.conv2 = RGCNConv(hidden_channels, out_channels, num_relations)\n",
    "        self.score_fn = Linear(out_channels * 2, 1)  # Scoring function for link prediction\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "    \n",
    "    def predict_link(self, x, edge_pairs):\n",
    "        h1 = x[edge_pairs[:, 0]]\n",
    "        h2 = x[edge_pairs[:, 1]]\n",
    "        scores = self.score_fn(torch.cat([h1, h2], dim=1))\n",
    "        return torch.sigmoid(scores).squeeze()\n",
    "\n",
    "# apparently the RGCN documentation said you should use negative sampling so this is what that does\n",
    "def generate_negative_edges(num_nodes, num_samples, existing_edges):\n",
    "    neg_edges = set()\n",
    "    while len(neg_edges) < num_samples:\n",
    "        u, v = random.randint(0, num_nodes - 1), random.randint(0, num_nodes - 1)\n",
    "        if (u, v) not in existing_edges and (v, u) not in existing_edges and u != v:\n",
    "            neg_edges.add((u, v))\n",
    "    return torch.tensor(list(neg_edges), dtype=torch.long)\n",
    "\n",
    "# train\n",
    "def train(model, data, x, epochs=100):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    \n",
    "    pos_edges = data.edge_index.t()\n",
    "    neg_edges = generate_negative_edges(data.num_nodes, pos_edges.shape[0], set(map(tuple, pos_edges.tolist())))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        embeddings = model(x, data.edge_index, data.edge_attr)\n",
    "        pos_scores = model.predict_link(embeddings, pos_edges)\n",
    "        neg_scores = model.predict_link(embeddings, neg_edges)\n",
    "        \n",
    "        labels = torch.cat([torch.ones(pos_scores.shape[0]), torch.zeros(neg_scores.shape[0])])\n",
    "        scores = torch.cat([pos_scores, neg_scores])\n",
    "        \n",
    "        loss = loss_fn(scores, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "# Modify the load_cpnet function to return cpnet_simple\n",
    "def load_cpnet():\n",
    "    global cpnet, cpnet_simple\n",
    "    print(\"Loading cpnet...\")\n",
    "    with open(cpnet_path, \"rb\") as f:\n",
    "        cpnet = pickle.load(f)\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Build an undirected version\n",
    "    cpnet_simple = nx.Graph()\n",
    "    for u, v, data in cpnet.edges(data=True):\n",
    "        w = data[\"weight\"] if \"weight\" in data else 1.0\n",
    "        if cpnet_simple.has_edge(u, v):\n",
    "            cpnet_simple[u][v][\"weight\"] += w\n",
    "        else:\n",
    "            cpnet_simple.add_edge(u, v, weight=w)\n",
    "    \n",
    "    return cpnet_simple, cpnet.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a887500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cpnet...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Now call the function and unpack the result\n",
    "cpnet_simple, edge_types = load_cpnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce6117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, rel_map = convert_to_pyg(cpnet_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d4908d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 669941\n"
     ]
    }
   ],
   "source": [
    "num_relations = len(rel_map)\n",
    "num_nodes = data.num_nodes\n",
    "print(str(num_relations) + \", \" + str(num_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e487521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RGCN(num_nodes, num_relations, in_channels=64, hidden_channels=128, out_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc5f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((num_nodes, 64), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd1b86fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7279093265533447\n",
      "Epoch 10, Loss: 0.6410232782363892\n",
      "Epoch 20, Loss: 0.4867541491985321\n",
      "Epoch 30, Loss: 0.3578296899795532\n",
      "Epoch 40, Loss: 0.3482210338115692\n",
      "Epoch 50, Loss: 0.3340449333190918\n",
      "Epoch 60, Loss: 0.3289547562599182\n",
      "Epoch 70, Loss: 0.3244965672492981\n",
      "Epoch 80, Loss: 0.3215307593345642\n",
      "Epoch 90, Loss: 0.31939268112182617\n"
     ]
    }
   ],
   "source": [
    "train(model, data, x, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "299c105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model(x, data.edge_index, data.edge_attr).detach()\n",
    "torch.save(embeddings, \"conceptnet_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "069ece68-3d8a-4fa0-8bc8-afe967fe4769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of computed embeddings: torch.Size([669941, 64])\n",
      "Max value in embeddings: 4.272341251373291\n",
      "Min value in embeddings: -4.3894429206848145\n",
      "Any NaNs? False\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model(x, data.edge_index, data.edge_attr)\n",
    "    print(\"Shape of computed embeddings:\", embeddings.shape)  # Should be (num_nodes, out_channels)\n",
    "    print(\"Max value in embeddings:\", embeddings.max().item())\n",
    "    print(\"Min value in embeddings:\", embeddings.min().item())\n",
    "    print(\"Any NaNs?\", torch.isnan(embeddings).any().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818dc2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f9834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_scratch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
